{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b4ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, ElementClickInterceptedException\n",
    "import time\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13890c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the URLs of movies's review page...\n",
      "Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=142.0.7444.163); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#staleelementreferenceexception\n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x7ff62587a235\n",
      "\t0x7ff6255d2630\n",
      "\t0x7ff6253616dd\n",
      "\t0x7ff6253694c8\n",
      "\t0x7ff62536c8c2\n",
      "\t0x7ff62540ce53\n",
      "\t0x7ff6253e2b0a\n",
      "\t0x7ff62540baba\n",
      "\t0x7ff6253ab0ed\n",
      "\t0x7ff6253abf63\n",
      "\t0x7ff6258a5d60\n",
      "\t0x7ff62589fe8a\n",
      "\t0x7ff6258c1005\n",
      "\t0x7ff6255ed71e\n",
      "\t0x7ff6255f4e1f\n",
      "\t0x7ff6255db7c4\n",
      "\t0x7ff6255db97f\n",
      "\t0x7ff6255c18e8\n",
      "\t0x7ffd1c38e8d7\n",
      "\t0x7ffd1cc4c53c\n",
      "\n",
      "Error ocurred, retrying. If still more errors, consider stopping the program and debug it\n",
      "Clicked all the extend buttons. Moving to the next step...\n",
      "found 1052 movies from the first table\n",
      "Got 1052 movie urls from the first table\n",
      "found 37 movies from the second table\n",
      "Got a total of 1056 unique movie urls from the 2 tables\n"
     ]
    }
   ],
   "source": [
    "# Get the URLs of movies's review on MoMo\n",
    "main_url = \"https://www.momo.vn/cinema/review?fromType=nav_menu\"\n",
    "movie_urls = set()\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(15)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "print(\"Getting the URLs of movies's review page...\")\n",
    "driver.get(main_url)\n",
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            show_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Xem tiếp')]\")))\n",
    "            show_button.click()\n",
    "        except TimeoutException:\n",
    "            print(\"Clicked all the extend buttons. Moving to the next step...\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error ocurred, retrying. If still more errors, consider stopping the program and debug it\")\n",
    "            continue\n",
    "\n",
    "    movie_table = driver.find_element(By.CSS_SELECTOR, \"#review div.grid\")\n",
    "    movie_elements = movie_table.find_elements(By.CSS_SELECTOR, \":scope > div\")\n",
    "    print(f'found {len(movie_elements)} movies from the first table')\n",
    "\n",
    "    for movie_element in movie_elements:\n",
    "        link_element = movie_element.find_element(By.TAG_NAME, \"a\")\n",
    "        href = link_element.get_attribute(\"href\")\n",
    "        movie_urls.add(href)\n",
    "    print(f'Got {len(movie_urls)} movie urls from the first table')\n",
    "\n",
    "    momo_movie_table = driver.find_element(By.CSS_SELECTOR, \"#reviewMoMo div.grid\")\n",
    "    momo_movie_elements = momo_movie_table.find_elements(By.CSS_SELECTOR, \":scope > div\")\n",
    "    print(f'found {len(momo_movie_elements)} movies from the second table')\n",
    "\n",
    "    for movie_element in momo_movie_elements:\n",
    "        link_element = movie_element.find_element(By.TAG_NAME, \"a\")\n",
    "        href = link_element.get_attribute(\"href\")\n",
    "        movie_urls.add(href)\n",
    "    print(f'Got a total of {len(movie_urls)} unique movie urls from the 2 tables')\n",
    "\n",
    "    driver.quit()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ae4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the crawled URLs\n",
    "with open ('movie_urls.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(list(movie_urls), f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d800fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ratings from every movie's review page...\n"
     ]
    }
   ],
   "source": [
    "# Go to each URL and crawl the ratings from comments\n",
    "with open ('movie_urls.json', 'r', encoding='utf-8') as f:\n",
    "    movie_urls = json.load(f)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.page_load_strategy = 'eager'\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.implicitly_wait(5)\n",
    "wait = WebDriverWait(driver, 5)\n",
    "\n",
    "failed_urls = []\n",
    "user_id_dict = {}\n",
    "user_idx = 1\n",
    "movie_idx = 1\n",
    "max_None = 30\n",
    "max_try = 5\n",
    "\n",
    "print(\"Extracting ratings from every movie's review page...\")\n",
    "movies_file = open(\"movies_metadata.csv\", \"a\", newline=\"\", encoding=\"utf-8\")\n",
    "movies_writer = csv.writer(movies_file)\n",
    "movies_writer.writerow(['id', 'name', 'genres', 'country', 'year', 'IMDb_score', 'MoMo_score'])\n",
    "\n",
    "ratings_file = open(\"ratings.csv\", \"a\", newline=\"\", encoding=\"utf-8\")\n",
    "ratings_writer = csv.writer(ratings_file)\n",
    "ratings_writer.writerow(['userId', 'movieId', 'rating', 'date'])\n",
    "\n",
    "for movie_url in movie_urls: # you can change this to movie_urls[:i] to save time if you are just testing\n",
    "    try:\n",
    "        driver.get(movie_url)\n",
    "    except Exception as e:\n",
    "        print(f\"took too long to load {movie_url}, skipping\")\n",
    "        failed_urls.append(movie_url)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        MoMo_score = IMDb_score = None\n",
    "        score_elements = driver \\\n",
    "            .find_element(By.CSS_SELECTOR, \"div.jsx-d074b6b0f0aeffcc.mt-1.flex\") \\\n",
    "            .find_elements(By.CSS_SELECTOR, \":scope > div\")\n",
    "        for score_element in score_elements:\n",
    "            score_sub_elements = score_element.find_elements(By.CSS_SELECTOR, \":scope > *\")\n",
    "            if score_sub_elements[0].find_element(By.CSS_SELECTOR, \":scope > *\").tag_name == 'img':\n",
    "                MoMo_score = score_sub_elements[1].text\n",
    "            elif \"h-auto\" in score_sub_elements[0].find_element(By.CSS_SELECTOR, \":scope > *\").get_attribute(\"class\"):\n",
    "                IMDb_score = score_sub_elements[1].text\n",
    "\n",
    "        if MoMo_score is not None:\n",
    "            info_element = driver.find_element(By.CSS_SELECTOR, 'div.jsx-d074b6b0f0aeffcc.flex-1')\n",
    "\n",
    "            name_element = info_element.find_element(By.TAG_NAME, \"a\")\n",
    "            name = name_element.text\n",
    "\n",
    "            further_info_elements = info_element.find_element(By.TAG_NAME, \"ul\").find_elements(By.CSS_SELECTOR, \":scope > li\")\n",
    "            genres = further_info_elements[0].text[12:]\n",
    "            year = further_info_elements[1].text[20:]\n",
    "            if len(further_info_elements) > 2:\n",
    "                country = further_info_elements[2].text[16:]\n",
    "            else:\n",
    "                country = None\n",
    "\n",
    "            tries = 0\n",
    "            pre_len = None\n",
    "            while tries <= max_try:\n",
    "                try:\n",
    "                    rating_elements = driver \\\n",
    "                        .find_element(By.CSS_SELECTOR, \"div.grid.grid-cols-1.divide-y\") \\\n",
    "                        .find_elements(By.CSS_SELECTOR, \":scope > div\")\n",
    "                    length = len(rating_elements)\n",
    "                    if pre_len is not None:\n",
    "                        if length == pre_len:\n",
    "                            tries += 1\n",
    "                            time.sleep(0.3)\n",
    "                            continue\n",
    "                        else:\n",
    "                            tries = 0\n",
    "                            pre_len = length\n",
    "                    else:\n",
    "                        pre_len = length\n",
    "\n",
    "                    show_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Xem tiếp nhé!')]\")))\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", show_button)\n",
    "                    time.sleep(0.8)\n",
    "                    show_button.click()\n",
    "                    time.sleep(0.2)\n",
    "                except TimeoutException:\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    print(f\"DOM while loading {movie_url}, retrying\")\n",
    "                    tries += 1\n",
    "                    if pre_len is not None:\n",
    "                        pre_len -= 1 \n",
    "                    time.sleep(0.2)\n",
    "                    continue\n",
    "                except ElementClickInterceptedException:\n",
    "                    print(f'ElementClickInterceptedException encountered while working with {movie_url}, retrying')\n",
    "                    tries += 1\n",
    "                    if pre_len is not None:\n",
    "                        pre_len -= 1 \n",
    "                    time.sleep(1.6)\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(movie_url)\n",
    "                    tries = max_try + 1\n",
    "                    break\n",
    "\n",
    "            if tries > max_try:\n",
    "                print(f\"retried too many times or error occured, skipping {movie_url}\")\n",
    "                failed_urls.append(movie_url)\n",
    "                continue\n",
    "            \n",
    "            None_count = 0\n",
    "            for rating_element in rating_elements:\n",
    "                if None_count > max_None:\n",
    "                    print(f\"Too many ratings with no point in {movie_url}, skipping the rest\")\n",
    "                    break\n",
    "                user_name = rating_element.find_element(By.CSS_SELECTOR, 'div.text-md').text\n",
    "                date = rating_element.find_element(By.CSS_SELECTOR, 'div.text-xs').text\n",
    "                try:\n",
    "                    rating = float(rating_element.find_element(By.CSS_SELECTOR, 'span.pl-0\\\\.5').text.split(\"/\")[0])\n",
    "                except Exception as e:\n",
    "                    rating = None\n",
    "                    None_count += 1\n",
    "\n",
    "                if rating is not None:\n",
    "                    if user_name not in user_id_dict:\n",
    "                        user_id_dict[user_name] = user_idx\n",
    "                        user_idx += 1\n",
    "                    ratings_writer.writerow([user_id_dict[user_name], movie_idx, rating, date])\n",
    "\n",
    "            movies_writer.writerow([movie_idx, name, genres, country, year, IMDb_score, MoMo_score])\n",
    "            movie_idx += 1\n",
    "            ratings_file.flush()\n",
    "            movies_file.flush()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed_urls.append(movie_url)\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "movies_file.close()\n",
    "ratings_file.close()\n",
    "\n",
    "with open(\"failed_urls.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(failed_urls, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the state for future use if neccessary\n",
    "state = {\n",
    "    \"user_id_dict\": user_id_dict,\n",
    "    \"user_idx\": user_idx,\n",
    "    \"movie_idx\": movie_idx\n",
    "}\n",
    "\n",
    "with open(\"crawl_state.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(state, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb569a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying the failed urls with a 'less eager' approach. Fail again and we will skip the URL forever\n",
      "Extracting ratings from every movie's review page...\n"
     ]
    }
   ],
   "source": [
    "# If there are any failures, run this to give them another try with a more careful approach\n",
    "# Note that this code is made to run only once, so any more failures and the URL will be skipped\n",
    "# This code also won't keep track of which failed URL got retried successfully\n",
    "print(\"Retrying the failed urls with a 'less eager' approach. Fail again and we will skip the URL forever\")\n",
    "\n",
    "with open ('failed_urls.json', 'r', encoding='utf-8') as f:\n",
    "    movie_urls = json.load(f)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.page_load_strategy = 'eager'\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.implicitly_wait(5)\n",
    "wait = WebDriverWait(driver, 5)\n",
    "\n",
    "with open(\"crawl_state.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    state = json.load(f)\n",
    "    user_id_dict = state[\"user_id_dict\"]\n",
    "    user_idx = state[\"user_idx\"]\n",
    "    movie_idx = state[\"movie_idx\"]\n",
    "max_None = 30\n",
    "max_try = 10\n",
    "\n",
    "print(\"Extracting ratings from every movie's review page...\")\n",
    "movies_file = open(\"movies_metadata.csv\", \"a\", newline=\"\", encoding=\"utf-8\")\n",
    "movies_writer = csv.writer(movies_file)\n",
    "\n",
    "ratings_file = open(\"ratings.csv\", \"a\", newline=\"\", encoding=\"utf-8\")\n",
    "ratings_writer = csv.writer(ratings_file)\n",
    "\n",
    "for movie_url in movie_urls:\n",
    "    try:\n",
    "        driver.get(movie_url)\n",
    "    except Exception as e:\n",
    "        print(f\"took too long to load {movie_url}, skipping\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        MoMo_score = IMDb_score = None\n",
    "        score_elements = driver \\\n",
    "            .find_element(By.CSS_SELECTOR, \"div.jsx-d074b6b0f0aeffcc.mt-1.flex\") \\\n",
    "            .find_elements(By.CSS_SELECTOR, \":scope > div\")\n",
    "        for score_element in score_elements:\n",
    "            score_sub_elements = score_element.find_elements(By.CSS_SELECTOR, \":scope > *\")\n",
    "            if score_sub_elements[0].find_element(By.CSS_SELECTOR, \":scope > *\").tag_name == 'img':\n",
    "                MoMo_score = score_sub_elements[1].text\n",
    "            elif \"h-auto\" in score_sub_elements[0].find_element(By.CSS_SELECTOR, \":scope > *\").get_attribute(\"class\"):\n",
    "                IMDb_score = score_sub_elements[1].text\n",
    "\n",
    "        if MoMo_score is not None:\n",
    "            info_element = driver.find_element(By.CSS_SELECTOR, 'div.jsx-d074b6b0f0aeffcc.flex-1')\n",
    "\n",
    "            name_element = info_element.find_element(By.TAG_NAME, \"a\")\n",
    "            name = name_element.text\n",
    "\n",
    "            further_info_elements = info_element.find_element(By.TAG_NAME, \"ul\").find_elements(By.CSS_SELECTOR, \":scope > li\")\n",
    "            genres = further_info_elements[0].text[12:]\n",
    "            year = further_info_elements[1].text[20:]\n",
    "            if len(further_info_elements) > 2:\n",
    "                country = further_info_elements[2].text[16:]\n",
    "            else:\n",
    "                country = None\n",
    "\n",
    "            tries = 0\n",
    "            pre_len = None\n",
    "            while tries <= max_try:\n",
    "                try:\n",
    "                    rating_elements = driver \\\n",
    "                        .find_element(By.CSS_SELECTOR, \"div.grid.grid-cols-1.divide-y\") \\\n",
    "                        .find_elements(By.CSS_SELECTOR, \":scope > div\")\n",
    "                    length = len(rating_elements)\n",
    "                    if pre_len is not None:\n",
    "                        if length == pre_len:\n",
    "                            tries += 1\n",
    "                            time.sleep(0.4)\n",
    "                            continue\n",
    "                        else:\n",
    "                            tries = 0\n",
    "                            pre_len = length\n",
    "                    else:\n",
    "                        pre_len = length\n",
    "\n",
    "                    show_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Xem tiếp nhé!')]\")))\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", show_button)\n",
    "                    time.sleep(0.8)\n",
    "                    show_button.click()\n",
    "                    time.sleep(0.4)\n",
    "                except TimeoutException:\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    print(f\"DOM while loading {movie_url}, retrying\")\n",
    "                    tries += 1\n",
    "                    if pre_len is not None:\n",
    "                        pre_len -= 1 \n",
    "                    time.sleep(0.8)\n",
    "                    continue\n",
    "                except ElementClickInterceptedException:\n",
    "                    print(f'ElementClickInterceptedException encountered while working with {movie_url}, retrying')\n",
    "                    tries += 1\n",
    "                    if pre_len is not None:\n",
    "                        pre_len -= 1 \n",
    "                    time.sleep(1.6)\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(movie_url)\n",
    "                    tries = max_try + 1\n",
    "                    break\n",
    "\n",
    "            if tries > max_try:\n",
    "                print(f\"retried too many times or error occured, skipping {movie_url}\")\n",
    "                continue\n",
    "            \n",
    "            None_count = 0\n",
    "            for rating_element in rating_elements:\n",
    "                if None_count > max_None:\n",
    "                    print(f\"Too many ratings with no point in {movie_url}, skipping the rest\")\n",
    "                    break\n",
    "                user_name = rating_element.find_element(By.CSS_SELECTOR, 'div.text-md').text\n",
    "                date = rating_element.find_element(By.CSS_SELECTOR, 'div.text-xs').text\n",
    "                try:\n",
    "                    rating = float(rating_element.find_element(By.CSS_SELECTOR, 'span.pl-0\\\\.5').text.split(\"/\")[0])\n",
    "                except Exception as e:\n",
    "                    rating = None\n",
    "                    None_count += 1\n",
    "\n",
    "                if rating is not None:\n",
    "                    if user_name not in user_id_dict:\n",
    "                        user_id_dict[user_name] = user_idx\n",
    "                        user_idx += 1\n",
    "                    ratings_writer.writerow([user_id_dict[user_name], movie_idx, rating, date])\n",
    "\n",
    "            movies_writer.writerow([movie_idx, name, genres, country, year, IMDb_score, MoMo_score])\n",
    "            movie_idx += 1\n",
    "            ratings_file.flush()\n",
    "            movies_file.flush()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed_urls.append(movie_url)\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "movies_file.close()\n",
    "ratings_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "918df1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"user_id_dict\": user_id_dict,\n",
    "    \"user_idx\": user_idx,\n",
    "    \"movie_idx\": movie_idx\n",
    "}\n",
    "\n",
    "with open(\"crawl_state.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(state, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
